[package]
name = "vllm_core"
version.workspace = true
edition.workspace = true
rust-version.workspace = true
authors.workspace = true
license.workspace = true
description = "Core LLM inference library using Candle framework"
repository = "https://github.com/your-org/vllm_inferencer"
keywords = ["llm", "inference", "candle", "phi", "ml"]
categories = ["machine-learning"]

[lints]
workspace = true

[lib]
name = "vllm_core"
path = "src/lib.rs"

[features]
default = ["enabled"]
enabled = []
full = [
  "enabled",
  "dep:candle-core",
  "dep:candle-nn",
  "dep:candle-transformers",
  "dep:hf-hub",
  "dep:safetensors",
  "dep:tokenizers",
  "dep:serde",
  "dep:serde_json",
  "dep:error_tools",
  "dep:workspace_tools",
]

[dependencies]
# ML Framework
candle-core = { workspace = true, optional = true }
candle-nn = { workspace = true, optional = true }
candle-transformers = { workspace = true, optional = true }

# Model Loading
hf-hub = { workspace = true, optional = true }
safetensors = { workspace = true, optional = true }

# Tokenization
tokenizers = { workspace = true, optional = true }

# Serialization
serde = { workspace = true, optional = true }
serde_json = { workspace = true, optional = true }

# Error Handling
error_tools = { workspace = true, optional = true }

# Secrets Management
workspace_tools = { workspace = true, optional = true }

[dev-dependencies]
# Test utilities (future)
